# ğŸš€ ä¼æ¥­å“¡å·¥ç®¡ç†ç³»çµ± - ç³»çµ±æ•´åˆèˆ‡éƒ¨ç½²æŒ‡å—

## ğŸ“‹ æ–‡æª”æ¦‚è¿°

æœ¬æŒ‡å—æä¾›å®Œæ•´çš„ç³»çµ±æ•´åˆèˆ‡éƒ¨ç½²æµç¨‹ï¼ŒåŒ…å«ï¼š
- é–‹ç™¼ç’°å¢ƒè¨­ç½®
- ç³»çµ±æ•´åˆæ­¥é©Ÿ
- éƒ¨ç½²æµç¨‹è©³è§£
- æ¸¬è©¦é©—è­‰æ–¹æ¡ˆ
- ç¶­è­·å‡ç´šç­–ç•¥

---

## ğŸ› ï¸ é–‹ç™¼ç’°å¢ƒè¨­ç½®

### 1. åŸºç¤ç’°å¢ƒè¦æ±‚

| çµ„ä»¶ | æœ€ä½ç‰ˆæœ¬ | æ¨è–¦ç‰ˆæœ¬ | èªªæ˜ |
|------|----------|----------|------|
| Node.js | 16.x | 20.x | JavaScripté‹è¡Œç’°å¢ƒ |
| npm | 8.x | 10.x | å¥—ä»¶ç®¡ç†å™¨ |
| Git | 2.30 | Latest | ç‰ˆæœ¬æ§åˆ¶ |
| PostgreSQL | 12 | 15 | ç”Ÿç”¢è³‡æ–™åº« |
| Redis | 6.0 | 7.0 | å¿«å–æœå‹™ |
| Docker | 20.10 | Latest | å®¹å™¨åŒ–éƒ¨ç½² |

### 2. é–‹ç™¼å·¥å…·æ¨è–¦

```bash
# VS Code æ“´å±•
- ESLint
- Prettier
- GitLens
- Docker
- Thunder Client (APIæ¸¬è©¦)
- PostgreSQL Explorer

# Chrome æ“´å±•
- React Developer Tools
- Redux DevTools
- Lighthouse
```

### 3. ç’°å¢ƒè®Šæ•¸é…ç½®

å‰µå»º `.env.development` æ–‡ä»¶ï¼š
```env
# ä¼ºæœå™¨é…ç½®
NODE_ENV=development
PORT=3000
HOST=localhost

# è³‡æ–™åº«é…ç½®
DB_TYPE=memory  # memory | postgres | mysql
DB_HOST=localhost
DB_PORT=5432
DB_NAME=employee_management_dev
DB_USER=dev_user
DB_PASSWORD=dev_password

# Redisé…ç½®
REDIS_URL=redis://localhost:6379

# JWTé…ç½®
JWT_SECRET=your-super-secret-jwt-key-for-development
JWT_EXPIRES_IN=7d
JWT_REFRESH_EXPIRES_IN=30d

# Telegramé…ç½®
TELEGRAM_BOT_TOKEN=process.env.TELEGRAM_BOT_TOKEN
TELEGRAM_BOSS_GROUP_ID=process.env.TELEGRAM_GROUP_ID
TELEGRAM_EMPLOYEE_GROUP_ID=-1002658082393

# Googleé…ç½®ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
GOOGLE_SHEETS_ID=your-sheets-id
GOOGLE_CREDENTIALS={"type":"service_account",...}

# ç³»çµ±é…ç½®
GPS_RADIUS=100
LATE_GRACE_MINUTES=10
MAX_LOGIN_ATTEMPTS=5
SESSION_TIMEOUT=3600000

# æ—¥èªŒé…ç½®
LOG_LEVEL=debug
LOG_FORMAT=json
LOG_MAX_SIZE=20m
LOG_MAX_FILES=14d

# é–‹ç™¼é…ç½®
ENABLE_SWAGGER=true
ENABLE_GRAPHQL=false
MOCK_GPS=true
MOCK_TELEGRAM=true
```

---

## ğŸ”„ ç³»çµ±æ•´åˆæ­¥é©Ÿ

### Phase 1: å°ˆæ¡ˆåˆå§‹åŒ–

```bash
# 1. å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/your-org/employee-management.git
cd employee-management

# 2. å®‰è£ä¾è³´
npm install

# 3. åˆå§‹åŒ–è³‡æ–™åº«
npm run db:init
npm run db:migrate
npm run db:seed

# 4. å•Ÿå‹•é–‹ç™¼æœå‹™
npm run dev
```

### Phase 2: å‰å¾Œç«¯æ•´åˆ

#### 2.1 APIæ•´åˆé…ç½®
```javascript
// frontend/js/config.js
const API_CONFIG = {
  baseURL: process.env.REACT_APP_API_URL || 'http://localhost:3000/api',
  timeout: 30000,
  headers: {
    'Content-Type': 'application/json'
  }
};

// APIè«‹æ±‚æ””æˆªå™¨
axios.interceptors.request.use(
  config => {
    const token = localStorage.getItem('token');
    if (token) {
      config.headers.Authorization = `Bearer ${token}`;
    }
    return config;
  },
  error => Promise.reject(error)
);

// APIå›æ‡‰æ””æˆªå™¨
axios.interceptors.response.use(
  response => response,
  error => {
    if (error.response?.status === 401) {
      // TokenéæœŸï¼Œå˜—è©¦åˆ·æ–°
      return refreshToken().then(() => {
        return axios.request(error.config);
      });
    }
    return Promise.reject(error);
  }
);
```

#### 2.2 ç‹€æ…‹ç®¡ç†æ•´åˆ
```javascript
// frontend/js/store/index.js
class AppStore {
  constructor() {
    this.state = {
      user: null,
      isAuthenticated: false,
      notifications: [],
      loading: false
    };
    this.subscribers = [];
  }

  setState(updates) {
    this.state = { ...this.state, ...updates };
    this.notify();
  }

  subscribe(callback) {
    this.subscribers.push(callback);
    return () => {
      this.subscribers = this.subscribers.filter(cb => cb !== callback);
    };
  }

  notify() {
    this.subscribers.forEach(callback => callback(this.state));
  }
}

const store = new AppStore();
export default store;
```

### Phase 3: ç¬¬ä¸‰æ–¹æœå‹™æ•´åˆ

#### 3.1 Telegram Botæ•´åˆ
```javascript
// backend/services/telegram.js
const TelegramBot = require('node-telegram-bot-api');

class TelegramService {
  constructor() {
    this.bot = new TelegramBot(process.env.TELEGRAM_BOT_TOKEN, {
      polling: false // ä½¿ç”¨Webhookè€Œéè¼ªè©¢
    });
    
    this.setupWebhook();
    this.setupCommands();
  }

  async setupWebhook() {
    const webhookUrl = `${process.env.APP_URL}/api/telegram/webhook`;
    await this.bot.setWebHook(webhookUrl);
  }

  setupCommands() {
    this.bot.setMyCommands([
      { command: '/status', description: 'æŸ¥çœ‹ç³»çµ±ç‹€æ…‹' },
      { command: '/revenue', description: 'æŸ¥çœ‹ä»Šæ—¥ç‡Ÿæ”¶' },
      { command: '/attendance', description: 'æŸ¥çœ‹å‡ºå‹¤ç‹€æ³' }
    ]);
  }

  async sendNotification(groupId, message, options = {}) {
    try {
      const defaultOptions = {
        parse_mode: 'HTML',
        disable_web_page_preview: true
      };
      
      await this.bot.sendMessage(
        groupId, 
        message, 
        { ...defaultOptions, ...options }
      );
    } catch (error) {
      console.error('Telegramé€šçŸ¥ç™¼é€å¤±æ•—:', error);
    }
  }
}
```

#### 3.2 Google Sheetsæ•´åˆï¼ˆå¯é¸ï¼‰
```javascript
// backend/services/googleSheets.js
const { google } = require('googleapis');

class GoogleSheetsService {
  constructor() {
    this.auth = new google.auth.GoogleAuth({
      credentials: JSON.parse(process.env.GOOGLE_CREDENTIALS),
      scopes: ['https://www.googleapis.com/auth/spreadsheets']
    });
    
    this.sheets = google.sheets({ version: 'v4', auth: this.auth });
    this.spreadsheetId = process.env.GOOGLE_SHEETS_ID;
  }

  async readData(range) {
    const response = await this.sheets.spreadsheets.values.get({
      spreadsheetId: this.spreadsheetId,
      range
    });
    return response.data.values;
  }

  async writeData(range, values) {
    await this.sheets.spreadsheets.values.update({
      spreadsheetId: this.spreadsheetId,
      range,
      valueInputOption: 'USER_ENTERED',
      requestBody: { values }
    });
  }

  async appendData(range, values) {
    await this.sheets.spreadsheets.values.append({
      spreadsheetId: this.spreadsheetId,
      range,
      valueInputOption: 'USER_ENTERED',
      insertDataOption: 'INSERT_ROWS',
      requestBody: { values }
    });
  }
}
```

### Phase 4: è³‡æ–™åº«é·ç§»

#### 4.1 å¾è¨˜æ†¶é«”åˆ°PostgreSQL
```javascript
// scripts/migrate-to-postgres.js
const { Pool } = require('pg');
const memoryData = require('../app.js').database;

async function migrate() {
  const pool = new Pool({
    connectionString: process.env.DATABASE_URL
  });

  const client = await pool.connect();
  
  try {
    await client.query('BEGIN');
    
    // é·ç§»å“¡å·¥è³‡æ–™
    for (const employee of memoryData.employees) {
      await client.query(`
        INSERT INTO employees (
          username, password_hash, name, id_number,
          department, position, role, store_name, hire_date
        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
        ON CONFLICT (username) DO NOTHING
      `, [
        employee.username,
        employee.password, // éœ€è¦å…ˆé€²è¡Œhashè™•ç†
        employee.name,
        employee.idNumber,
        employee.department,
        employee.position,
        employee.role,
        'defaultStore',
        employee.hireDate || new Date()
      ]);
    }
    
    // é·ç§»å…¶ä»–è³‡æ–™è¡¨...
    console.log('âœ… è³‡æ–™é·ç§»æˆåŠŸ');
    
    await client.query('COMMIT');
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('âŒ è³‡æ–™é·ç§»å¤±æ•—:', error);
    throw error;
  } finally {
    client.release();
  }
}

migrate().catch(console.error);
```

---

## ğŸš¢ éƒ¨ç½²æµç¨‹è©³è§£

### 1. Dockerå®¹å™¨åŒ–éƒ¨ç½²

#### 1.1 Dockerfileå„ªåŒ–
```dockerfile
# å¤šéšæ®µæ§‹å»ºå„ªåŒ–æ˜ åƒå¤§å°
FROM node:20-alpine AS builder

# å®‰è£æ§‹å»ºä¾è³´
RUN apk add --no-cache python3 make g++

WORKDIR /app

# è¤‡è£½å¥—ä»¶æ–‡ä»¶
COPY package*.json ./

# å®‰è£ä¾è³´
RUN npm ci --only=production

# è¤‡è£½æºç¢¼
COPY . .

# æ§‹å»ºå‰ç«¯è³‡æº
RUN npm run build

# ç”Ÿç”¢éšæ®µ
FROM node:20-alpine

# å®‰è£é‹è¡Œæ™‚ä¾è³´
RUN apk add --no-cache dumb-init

# å‰µå»ºérootç”¨æˆ¶
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001

WORKDIR /app

# è¤‡è£½æ§‹å»ºçµæœ
COPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nodejs:nodejs /app/dist ./dist
COPY --from=builder --chown=nodejs:nodejs /app/public ./public
COPY --chown=nodejs:nodejs package*.json ./

# åˆ‡æ›ç”¨æˆ¶
USER nodejs

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD node healthcheck.js

# ä½¿ç”¨dumb-initè™•ç†ä¿¡è™Ÿ
ENTRYPOINT ["dumb-init", "--"]

# å•Ÿå‹•æ‡‰ç”¨
CMD ["node", "dist/app.js"]
```

#### 1.2 Docker Composeé…ç½®
```yaml
version: '3.9'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    image: employee-management:latest
    container_name: employee-management-app
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: production
      DATABASE_URL: postgres://user:pass@postgres:5432/employee_db
      REDIS_URL: redis://redis:6379
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - app-network
    volumes:
      - ./logs:/app/logs
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:15-alpine
    container_name: employee-management-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: employee_db
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: employee-management-cache
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    networks:
      - app-network

  nginx:
    image: nginx:alpine
    container_name: employee-management-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./public:/usr/share/nginx/html
    depends_on:
      - app
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
```

### 2. Kuberneteséƒ¨ç½²

#### 2.1 éƒ¨ç½²é…ç½®
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: employee-management
  labels:
    app: employee-management
spec:
  replicas: 3
  selector:
    matchLabels:
      app: employee-management
  template:
    metadata:
      labels:
        app: employee-management
    spec:
      containers:
      - name: app
        image: your-registry/employee-management:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: jwt-secret
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
```

#### 2.2 æœå‹™é…ç½®
```yaml
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: employee-management-service
spec:
  selector:
    app: employee-management
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
  type: LoadBalancer
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: employee-management-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.company.com
    secretName: employee-management-tls
  rules:
  - host: api.company.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: employee-management-service
            port:
              number: 80
```

### 3. CI/CD Pipeline

#### 3.1 GitHub Actions
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run tests
      run: npm test
    
    - name: Run linter
      run: npm run lint
    
    - name: Build application
      run: npm run build

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    - name: Build and push
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: |
          ${{ secrets.DOCKER_USERNAME }}/employee-management:latest
          ${{ secrets.DOCKER_USERNAME }}/employee-management:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    
    steps:
    - name: Deploy to Kubernetes
      uses: azure/k8s-deploy@v4
      with:
        manifests: |
          k8s/deployment.yaml
          k8s/service.yaml
        images: |
          ${{ secrets.DOCKER_USERNAME }}/employee-management:${{ github.sha }}
```

---

## ğŸ§ª æ¸¬è©¦é©—è­‰æ–¹æ¡ˆ

### 1. å–®å…ƒæ¸¬è©¦

```javascript
// tests/unit/auth.test.js
describe('Authentication Service', () => {
  let authService;
  
  beforeEach(() => {
    authService = new AuthService();
  });
  
  describe('login', () => {
    it('should return token for valid credentials', async () => {
      const result = await authService.login('john.doe', 'password123');
      
      expect(result).toHaveProperty('token');
      expect(result).toHaveProperty('user');
      expect(result.user.username).toBe('john.doe');
    });
    
    it('should throw error for invalid credentials', async () => {
      await expect(
        authService.login('john.doe', 'wrongpassword')
      ).rejects.toThrow('Invalid credentials');
    });
  });
  
  describe('validateToken', () => {
    it('should return user for valid token', async () => {
      const token = 'valid.jwt.token';
      const user = await authService.validateToken(token);
      
      expect(user).toHaveProperty('id');
      expect(user).toHaveProperty('username');
    });
  });
});
```

### 2. æ•´åˆæ¸¬è©¦

```javascript
// tests/integration/api.test.js
describe('API Integration Tests', () => {
  let app;
  let token;
  
  beforeAll(async () => {
    app = await createApp();
    
    // ç²å–æ¸¬è©¦token
    const response = await request(app)
      .post('/api/auth/login')
      .send({
        username: 'test.user',
        password: 'test123'
      });
    
    token = response.body.data.token;
  });
  
  describe('POST /api/attendance/clock-in', () => {
    it('should record clock-in successfully', async () => {
      const response = await request(app)
        .post('/api/attendance/clock-in')
        .set('Authorization', `Bearer ${token}`)
        .send({
          storeName: 'æ¸¬è©¦åº—',
          gpsCoordinates: {
            latitude: 24.9748412,
            longitude: 121.2556713
          }
        });
      
      expect(response.status).toBe(200);
      expect(response.body.success).toBe(true);
      expect(response.body.data).toHaveProperty('clockTime');
    });
  });
});
```

### 3. E2Eæ¸¬è©¦

```javascript
// tests/e2e/login-flow.test.js
describe('Login Flow E2E', () => {
  beforeEach(async () => {
    await page.goto('http://localhost:3000');
  });
  
  it('should login successfully with valid credentials', async () => {
    // è¼¸å…¥å¸³è™Ÿå¯†ç¢¼
    await page.type('#username', 'john.doe');
    await page.type('#password', 'password123');
    
    // é»æ“Šç™»å…¥
    await page.click('#login-button');
    
    // ç­‰å¾…è·³è½‰
    await page.waitForNavigation();
    
    // é©—è­‰ç™»å…¥æˆåŠŸ
    const url = page.url();
    expect(url).toBe('http://localhost:3000/dashboard');
    
    const welcomeText = await page.$eval('.welcome-message', el => el.textContent);
    expect(welcomeText).toContain('æ­¡è¿, ç´„ç¿°Â·å¤šä¼Š');
  });
});
```

### 4. æ•ˆèƒ½æ¸¬è©¦

```javascript
// tests/performance/load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 100 }, // æ¼¸å¢åˆ°100ç”¨æˆ¶
    { duration: '5m', target: 100 }, // ç¶­æŒ100ç”¨æˆ¶
    { duration: '2m', target: 0 },   // æ¼¸æ¸›åˆ°0
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%è«‹æ±‚åœ¨500mså…§
    http_req_failed: ['rate<0.1'],    // éŒ¯èª¤ç‡ä½æ–¼10%
  },
};

export default function () {
  // ç™»å…¥
  const loginRes = http.post('http://localhost:3000/api/auth/login', {
    username: 'test.user',
    password: 'test123',
  });
  
  check(loginRes, {
    'login successful': (r) => r.status === 200,
  });
  
  const token = loginRes.json('data.token');
  
  // æ‰“å¡
  const clockInRes = http.post(
    'http://localhost:3000/api/attendance/clock-in',
    {
      storeName: 'æ¸¬è©¦åº—',
      gpsCoordinates: {
        latitude: 24.9748412,
        longitude: 121.2556713,
      },
    },
    {
      headers: { Authorization: `Bearer ${token}` },
    }
  );
  
  check(clockInRes, {
    'clock-in successful': (r) => r.status === 200,
  });
  
  sleep(1);
}
```

---

## ğŸ”§ ç¶­è­·å‡ç´šç­–ç•¥

### 1. è³‡æ–™åº«ç¶­è­·

```sql
-- å®šæœŸç¶­è­·è…³æœ¬
-- daily-maintenance.sql

-- æ¸…ç†éæœŸæœƒè©±
DELETE FROM sessions WHERE expires_at < NOW();

-- æ›´æ–°çµ±è¨ˆè³‡è¨Š
ANALYZE;

-- æ¸…ç†å¯©è¨ˆæ—¥èªŒï¼ˆä¿ç•™90å¤©ï¼‰
DELETE FROM audit_logs WHERE created_at < NOW() - INTERVAL '90 days';

-- æ›´æ–°å“¡å·¥å·¥ä½œå¤©æ•¸
UPDATE employees e
SET total_work_days = (
    SELECT COUNT(DISTINCT DATE(clock_time))
    FROM attendance_records
    WHERE employee_id = e.id
    AND clock_type = 'ä¸Šç­'
);

-- æª¢æŸ¥ä¸¦ä¿®å¾©ç´¢å¼•
REINDEX TABLE employees;
REINDEX TABLE attendance_records;
```

### 2. ç‰ˆæœ¬å‡ç´šæµç¨‹

```bash
#!/bin/bash
# upgrade.sh

# 1. å‚™ä»½ç¾æœ‰è³‡æ–™
echo "ğŸ“¦ å‚™ä»½è³‡æ–™åº«..."
pg_dump $DATABASE_URL > backup-$(date +%Y%m%d-%H%M%S).sql

# 2. é€šçŸ¥ç¶­è­·æ¨¡å¼
echo "ğŸ”§ å•Ÿç”¨ç¶­è­·æ¨¡å¼..."
kubectl scale deployment employee-management --replicas=0

# 3. åŸ·è¡Œè³‡æ–™åº«é·ç§»
echo "ğŸ”„ åŸ·è¡Œè³‡æ–™åº«é·ç§»..."
npm run db:migrate

# 4. æ›´æ–°æ‡‰ç”¨
echo "ğŸš€ éƒ¨ç½²æ–°ç‰ˆæœ¬..."
kubectl set image deployment/employee-management \
  app=your-registry/employee-management:$NEW_VERSION

# 5. ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl rollout status deployment/employee-management

# 6. åŸ·è¡Œå¥åº·æª¢æŸ¥
echo "ğŸ¥ åŸ·è¡Œå¥åº·æª¢æŸ¥..."
./scripts/health-check.sh

# 7. æ¢å¾©æœå‹™
echo "âœ… æ¢å¾©æœå‹™..."
kubectl scale deployment employee-management --replicas=3
```

### 3. ç›£æ§å‘Šè­¦è¨­ç½®

```yaml
# prometheus-rules.yaml
groups:
  - name: employee-management
    rules:
    - alert: HighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "é«˜éŒ¯èª¤ç‡å‘Šè­¦"
        description: "5xxéŒ¯èª¤ç‡è¶…é5%"
    
    - alert: HighResponseTime
      expr: histogram_quantile(0.95, http_request_duration_seconds_bucket) > 1
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "éŸ¿æ‡‰æ™‚é–“éé•·"
        description: "95%è«‹æ±‚éŸ¿æ‡‰æ™‚é–“è¶…é1ç§’"
    
    - alert: LowDiskSpace
      expr: node_filesystem_avail_bytes / node_filesystem_size_bytes < 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "ç£ç¢Ÿç©ºé–“ä¸è¶³"
        description: "å¯ç”¨ç£ç¢Ÿç©ºé–“ä½æ–¼10%"
```

### 4. ç½é›£æ¢å¾©è¨ˆåŠƒ

```markdown
## ç½é›£æ¢å¾©ç¨‹åº

### 1. è³‡æ–™åº«å´©æ½°æ¢å¾©
1. åœæ­¢æ‡‰ç”¨æœå‹™é˜²æ­¢è³‡æ–™å¯«å…¥
2. å¾æœ€è¿‘çš„å‚™ä»½æ¢å¾©è³‡æ–™åº«
3. æ‡‰ç”¨å¢é‡æ—¥èªŒï¼ˆå¦‚æœæœ‰ï¼‰
4. é©—è­‰è³‡æ–™å®Œæ•´æ€§
5. é‡å•Ÿæ‡‰ç”¨æœå‹™

### 2. æœå‹™å®Œå…¨ä¸­æ–·æ¢å¾©
1. å•Ÿå‹•å‚™ç”¨ç’°å¢ƒ
2. æ›´æ–°DNSæŒ‡å‘å‚™ç”¨ç’°å¢ƒ
3. æ¢å¾©ä¸»ç’°å¢ƒ
4. è³‡æ–™åŒæ­¥
5. åˆ‡æ›å›ä¸»ç’°å¢ƒ

### 3. è³‡æ–™æ´©éœ²æ‡‰æ€¥éŸ¿æ‡‰
1. ç«‹å³éš”é›¢å—å½±éŸ¿ç³»çµ±
2. é‡ç½®æ‰€æœ‰å¯†ç¢¼å’Œé‡‘é‘°
3. å¯©æŸ¥è¨ªå•æ—¥èªŒ
4. é€šçŸ¥ç›¸é—œäººå“¡
5. é€²è¡Œå®‰å…¨å¯©è¨ˆ
```

---

## ğŸ“ˆ æ•ˆèƒ½å„ªåŒ–å»ºè­°

### 1. å‰ç«¯å„ªåŒ–

```javascript
// åœ–ç‰‡æ‡¶åŠ è¼‰
const imageObserver = new IntersectionObserver((entries, observer) => {
  entries.forEach(entry => {
    if (entry.isIntersecting) {
      const img = entry.target;
      img.src = img.dataset.src;
      observer.unobserve(img);
    }
  });
});

document.querySelectorAll('img[data-src]').forEach(img => {
  imageObserver.observe(img);
});

// ç¨‹å¼ç¢¼åˆ†å‰²
const routes = {
  '/dashboard': () => import('./modules/dashboard.js'),
  '/attendance': () => import('./modules/attendance.js'),
  '/revenue': () => import('./modules/revenue.js')
};

// Service Workerå¿«å–
self.addEventListener('install', event => {
  event.waitUntil(
    caches.open('v1').then(cache => {
      return cache.addAll([
        '/',
        '/css/style.css',
        '/js/app.js',
        '/images/logo.png'
      ]);
    })
  );
});
```

### 2. å¾Œç«¯å„ªåŒ–

```javascript
// è³‡æ–™åº«æŸ¥è©¢å„ªåŒ–
class EmployeeRepository {
  async getEmployeesWithPagination(page, limit) {
    const offset = (page - 1) * limit;
    
    const query = `
      SELECT 
        e.*,
        COUNT(*) OVER() as total_count
      FROM employees e
      WHERE e.status = 'active'
      ORDER BY e.name
      LIMIT $1 OFFSET $2
    `;
    
    const result = await db.query(query, [limit, offset]);
    
    return {
      data: result.rows,
      total: result.rows[0]?.total_count || 0,
      page,
      limit
    };
  }
}

// Rediså¿«å–å±¤
class CacheService {
  async get(key) {
    const cached = await redis.get(key);
    return cached ? JSON.parse(cached) : null;
  }
  
  async set(key, value, ttl = 300) {
    await redis.setex(key, ttl, JSON.stringify(value));
  }
  
  async invalidate(pattern) {
    const keys = await redis.keys(pattern);
    if (keys.length > 0) {
      await redis.del(...keys);
    }
  }
}

// ä½¿ç”¨å¿«å–è£é£¾å™¨
function Cacheable(ttl = 300) {
  return function(target, propertyKey, descriptor) {
    const originalMethod = descriptor.value;
    
    descriptor.value = async function(...args) {
      const cacheKey = `${target.constructor.name}:${propertyKey}:${JSON.stringify(args)}`;
      
      const cached = await cacheService.get(cacheKey);
      if (cached) return cached;
      
      const result = await originalMethod.apply(this, args);
      await cacheService.set(cacheKey, result, ttl);
      
      return result;
    };
  };
}
```

---

## ğŸ¯ ç¸½çµ

æœ¬éƒ¨ç½²æŒ‡å—æ¶µè“‹äº†å¾é–‹ç™¼åˆ°ç”Ÿç”¢çš„å®Œæ•´æµç¨‹ï¼š

1. **ç’°å¢ƒè¨­ç½®**ï¼šè©³ç´°çš„é–‹ç™¼ç’°å¢ƒé…ç½®
2. **ç³»çµ±æ•´åˆ**ï¼šå‰å¾Œç«¯åŠç¬¬ä¸‰æ–¹æœå‹™æ•´åˆ
3. **éƒ¨ç½²æ–¹æ¡ˆ**ï¼šDockerã€Kubernetesç­‰å¤šç¨®éƒ¨ç½²é¸æ“‡
4. **æ¸¬è©¦ç­–ç•¥**ï¼šå®Œæ•´çš„æ¸¬è©¦é‡‘å­—å¡”
5. **ç¶­è­·è¨ˆåŠƒ**ï¼šæŒçºŒçš„ç³»çµ±ç¶­è­·å’Œå„ªåŒ–

éµå¾ªæœ¬æŒ‡å—å¯ä»¥ç¢ºä¿ç³»çµ±ç©©å®šã€é«˜æ•ˆåœ°é‹è¡Œåœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ã€‚

---

**æ–‡æª”ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¥æœŸ**: 2025-01-10  
**DevOpsåœ˜éšŠ**: AIé–‹ç™¼å°çµ„